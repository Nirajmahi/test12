{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a6972d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3727a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 3\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00747cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94aa2d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(words, C):\n",
    "    \"\"\"\n",
    "    A generator function to yield context words and center words.\n",
    "\n",
    "    Parameters:\n",
    "    - words: a list of words from a sentence.\n",
    "    - C: the context size; the number of words to consider on each side of the center word.\n",
    "\n",
    "    Yields:\n",
    "    - context_words: a list of words around the center word, excluding the center word.\n",
    "    - center_word: the word in the middle of the context.\n",
    "    \"\"\"\n",
    "    i = C\n",
    "    while i < len(words) - C:\n",
    "        center_word = words[i]\n",
    "        context_words = words[(i - C):i] + words[(i + 1):(i + C + 1)]\n",
    "        yield context_words, center_word\n",
    "        i += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "C=1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb4174",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(data) > 0        \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40a411df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(data_point_index, vocabsize):\n",
    "    temp = np.zeros(vocabsize)\n",
    "    temp[data_point_index] = 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "519c8e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file1 = r'C:\\Users\\CCC-PC\\Desktop\\final_review_dataset.csv'\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(file1, on_bad_lines='skip', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e8ba61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.sample(n=100, random_state=42)  # Adjust random_state for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6a21838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 200710 to 252037\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   overall       100 non-null    float64\n",
      " 1   reviewText    100 non-null    object \n",
      " 2   review_label  100 non-null    int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 3.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dad285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4bf75c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     box says works   feet away   nt tested yetbut ...\n",
       "1                                 product registeration\n",
       "2     overall wierd movie   saw description guide sa...\n",
       "3                                            piece junk\n",
       "4     mark hamon character twist   turns worth purchase\n",
       "                            ...                        \n",
       "95                                           ugly weird\n",
       "96                 router good wireless card nt connect\n",
       "97                                        great cameras\n",
       "98    finally clint eastwood movie belong dirty harr...\n",
       "99                                best car receiver far\n",
       "Name: reviewText, Length: 100, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['reviewText']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29b75966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in wordList: 3249\n",
      "Total number of unique words in vocabulary: 1952\n"
     ]
    }
   ],
   "source": [
    "wordList = []  # Initialize an empty list to store all words\n",
    "vocabulary = set()  # Initialize an empty set to store unique words\n",
    "\n",
    "for review_text in df1['reviewText']:\n",
    "    words = review_text.split()  # Tokenize the text into words\n",
    "    wordList.extend(words)  # Add all words to wordList\n",
    "    vocabulary.update(words)  # Add unique words to the vocabulary set\n",
    "\n",
    "print(\"Total number of words in wordList:\", len(wordList))\n",
    "print(\"Total number of unique words in vocabulary:\", len(vocabulary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ee84c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabsize= len(vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48e54bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_2_int={}\n",
    "int_2_word={}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dea8f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e38fceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in wordList: 1952\n",
      "Number of words in word2int: 1952\n",
      "Number of indices in int2word: 1952\n"
     ]
    }
   ],
   "source": [
    "wordList = list(vocabulary)  # Assuming vocabulary contains the unique words\n",
    "print(\"Number of words in wordList:\", len(wordList))\n",
    "word_2_int={}\n",
    "int_2_word={}\n",
    "for i, word in enumerate(wordList):\n",
    "    word_2_int[word] = i  \n",
    "    int_2_word[i] = word\n",
    "\n",
    "print(\"Number of words in word2int:\", len(word_2_int))\n",
    "print(\"Number of indices in int2word:\", len(int_2_word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a80f0087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3052\n",
      "3052\n",
      "100\n",
      "['box', 'works']\n"
     ]
    }
   ],
   "source": [
    "context_data = []\n",
    "senti_data = []\n",
    "center_data=[]\n",
    "i = 0\n",
    "for index, row in df1.iterrows():\n",
    "    \n",
    "  \n",
    "    words = row['reviewText'].split()\n",
    "    sentiment_label = row['review_label']\n",
    "   \n",
    "\n",
    "    for context_words, center_word  in get_windows(words, C):\n",
    "        context_data.append(context_words)\n",
    "        senti_data.append(sentiment_label)\n",
    "        center_data.append(center_word)\n",
    "    i=i+1\n",
    "#print(context_data)\n",
    "#print(senti_data)\n",
    "print(len(context_data))\n",
    "print(len(senti_data))\n",
    "print(i)\n",
    "print(context_data[0])\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b758b4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "context_data_hot = []\n",
    "\n",
    "center_data_hot=[]\n",
    "\n",
    "i=0\n",
    "\n",
    "for context_word,center_word in zip(context_data,center_data):\n",
    "    \n",
    "    \n",
    "    \n",
    "    context_words_vectors = [to_one_hot(word_2_int[w], vocabsize) for w in context_word]\n",
    "    context_data_hot.append(np.mean(context_words_vectors,axis=0))\n",
    "    center_data_hot.append(to_one_hot(word_2_int[center_word], vocabsize))\n",
    "    \n",
    "    i=i+1\n",
    "print(len( context_words_vectors ))\n",
    "print(context_data_hot[0])\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b7e5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(batch_size):\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    batch_senti=[]\n",
    "    for x, y,z in zip ( context_data_hot,center_data_hot,senti_data):\n",
    "        while len(batch_x) < batch_size:\n",
    "            batch_x.append(x)\n",
    "            batch_y.append(y)\n",
    "            batch_senti.append(z)\n",
    "        else:\n",
    "            yield np.array(batch_x).T, np.array(batch_y).T,np.array(batch_senti).T\n",
    "            batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1737422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1952, 7)\n",
      "(1952, 7)\n",
      "(7,)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "for x,y, z in get_batches(7):\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(z.shape)\n",
    "    i=i+1\n",
    "    if i==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ea93ceb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.])]\n",
      "3052\n"
     ]
    }
   ],
   "source": [
    "print(type(context_data_hot))\n",
    "print(context_data_hot[0])\n",
    "print(len(senti_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91bbc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8e677ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "The lists are not equal\n",
      "1952\n",
      "1952\n"
     ]
    }
   ],
   "source": [
    "  # Find the index where the 1 is located\n",
    "index_of_one = np.argmax(context_data_hot[0])\n",
    "print(index_of_one)\n",
    "cont =[]\n",
    "cont.append(to_one_hot(word_2_int['box'],vocabsize))\n",
    "cont.append (to_one_hot(word_2_int['works'],vocabsize))\n",
    "mean = []\n",
    "mean.append(np.mean(cont,axis=0))\n",
    "print(mean[0])\n",
    "\n",
    "if len(context_words_vectors[1]) == len(cont[1]) and all(np.array_equal(a, b) for a, b in zip(context_data_hot[0], mean[0])):\n",
    "    print(\"The lists are equal\")\n",
    "else:\n",
    "    print(\"The lists are not equal\")\n",
    "print(len(mean[0]))\n",
    "print(len(cont[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7d18eebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(center_data_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "72705b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = np.array(center_data_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b5b7e52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3052, 1952)\n"
     ]
    }
   ],
   "source": [
    "print(type(target))\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0a581b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_level = np.array(senti_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "57bdb3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3052,)\n"
     ]
    }
   ],
   "source": [
    "print(type(senti_level))\n",
    "print(senti_level.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "278ff087",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = np.array(context_data_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "48fb4dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c2c65e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3052, 2, 1952)\n"
     ]
    }
   ],
   "source": [
    "print(type(context))\n",
    "print(context.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4f0d3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test,Senti_train,Senti_test = train_test_split(context,target,senti_level, test_size=0.8, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9875e683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610, 2, 1952)\n",
      "(610, 1952)\n",
      "(610,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(Senti_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ca6dffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "vocab_size = vocabsize  \n",
    "embedding_dim = 300  \n",
    "window_size = 3 \n",
    "batch_size = 128  \n",
    "num_epochs = 10  \n",
    "p = 0.5 \n",
    "beta = 0.5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0df1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7127a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDSAWESModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CDSAWESModel, self).__init__()\n",
    "        # Initialize the embedding matrix\n",
    "        self.W_s = tf.Variable(tf.random.normal([vocab_size, embedding_dim]))\n",
    "        self.U = tf.Variable(tf.random.normal([vocab_size, embedding_dim]))  # for CBOW\n",
    "        self.context_weights = tf.Variable(tf.random.normal([embedding_dim, 1]))  # for sentiment analysis\n",
    "\n",
    "    def call(self, context, corrupt=True):\n",
    "        # Context is a batch of context windows\n",
    "\n",
    "        # Apply corruption operation (Eq. 1)\n",
    "        if corrupt:\n",
    "            mask = tf.cast(tf.random.uniform(shape=context.shape) > p, tf.float32)\n",
    "            context = context * mask\n",
    "\n",
    "        # Compute mean context vector (Eq. 2)\n",
    "        x_hat = tf.reduce_mean(context, axis=1,keepdims=True)\n",
    "        print(x_hat.shape)\n",
    "\n",
    "        # Predict center word (Eq. 4)\n",
    "        logits = tf.matmul(x_hat, self.U, transpose_b=True)\n",
    "\n",
    "        # Predict sentiment (using a similar method as context prediction)\n",
    "        sentiment_logits = tf.matmul(x_hat, self.context_weights)\n",
    "\n",
    "        return logits, sentiment_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ec749ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CDSAWESModel(vocab_size, embedding_dim)\n",
    "\n",
    "# Define loss functions (Eq. 5, Eq. 6)\n",
    "loss_fn_cbow = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_fn_sentiment = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4fbf16d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Y_train_center \u001b[38;5;241m=\u001b[39m \u001b[43mY_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCenter_word\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues  \u001b[38;5;66;03m# Extract the 'Center_word' column as center words\u001b[39;00m\n\u001b[0;32m      2\u001b[0m Y_train_sentiment \u001b[38;5;241m=\u001b[39m Y_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentiment_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues \n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "Y_train_center = Y_train['Center_word'].values  # Extract the 'Center_word' column as center words\n",
    "Y_train_sentiment = Y_train['Sentiment_label'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4eca8f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "context_list = X_train['Context'].tolist()\n",
    "\n",
    "# Pad the sequences so that each one has the same length\n",
    "max_length = max(len(x) for x in context_list)  # This assumes all lists should be padded to the length of the longest list\n",
    "padded_context_list = pad_sequences(context_list, maxlen=max_length, padding='post', dtype='float32')\n",
    "\n",
    "# Now convert the padded list to a tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c301e836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3052, 1, 1952)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'cdsawes_model_4' (type CDSAWESModel).\n\n{{function_node __wrapped____MklBatchMatMulV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [3052,1,1952], In[1]: [1952,300] 0 1 [Op:BatchMatMulV2] name: \n\nCall arguments received by layer 'cdsawes_model_4' (type CDSAWESModel):\n  • context=tf.Tensor(shape=(3052, 2, 1952), dtype=float32)\n  • corrupt=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m sentiment_batch \u001b[38;5;241m=\u001b[39m Senti_train[batch \u001b[38;5;241m*\u001b[39m batch_size: (batch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m logits, sentiment_logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[0;32m     18\u001b[0m loss_cbow \u001b[38;5;241m=\u001b[39m loss_fn_cbow(center_batch, logits)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[111], line 22\u001b[0m, in \u001b[0;36mCDSAWESModel.call\u001b[1;34m(self, context, corrupt)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_hat\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Predict center word (Eq. 4)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Predict sentiment (using a similar method as context prediction)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m sentiment_logits \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmatmul(x_hat, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_weights)\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'cdsawes_model_4' (type CDSAWESModel).\n\n{{function_node __wrapped____MklBatchMatMulV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [3052,1,1952], In[1]: [1952,300] 0 1 [Op:BatchMatMulV2] name: \n\nCall arguments received by layer 'cdsawes_model_4' (type CDSAWESModel):\n  • context=tf.Tensor(shape=(3052, 2, 1952), dtype=float32)\n  • corrupt=True"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in range(batch_size):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Get a batch of context and targets\n",
    "            \n",
    "            context_batch = X_train[batch * batch_size: (batch + 1) * batch_size]\n",
    "\n",
    "            context_batch = tf.convert_to_tensor(context, dtype=tf.float32)\n",
    "\n",
    "            center_batch = Y_train[batch * batch_size: (batch + 1) * batch_size]\n",
    "            sentiment_batch = Senti_train[batch * batch_size: (batch + 1) * batch_size]\n",
    "\n",
    "            # Forward pass\n",
    "            logits, sentiment_logits = model(context_batch)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss_cbow = loss_fn_cbow(center_batch, logits)\n",
    "            loss_sentiment = loss_fn_sentiment(sentiment_batch, sentiment_logits)\n",
    "            total_loss = beta * loss_cbow + (1 - beta) * loss_sentiment\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {batch}, Loss: {total_loss.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1a005e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define hyperparameters\n",
    "vocab_size = 10000  # Assuming a vocabulary size of 10,000\n",
    "embedding_dim = 300  # Embedding size for each word\n",
    "beta = 0.5  # Balance hyperparameter for loss combination\n",
    "corruption_prob = 0.5  # Corruption probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "446e46c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CDSAWES model\n",
    "class CDSAWESModel1(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CDSAWESModel1, self).__init__()\n",
    "        self.dropout = Dropout(corruption_prob)  # Apply corruption as dropout to the input layer\n",
    "        self.embedding = Dense(embedding_dim, activation='relu')  # A dense layer as an embedding layer\n",
    "        self.semantic_output = Dense(vocab_size, activation='softmax')  # Predicts the center word\n",
    "        self.sentiment_output = Dense(1, activation='sigmoid')  # Binary sentiment classification\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        corrupted = self.dropout(inputs, training=training)  # Apply corruption only during training\n",
    "        embeddings = self.embedding(corrupted)\n",
    "        # Sum the embeddings to represent the context\n",
    "        context = tf.reduce_sum(embeddings, axis=1)\n",
    "        # Two separate outputs\n",
    "        center_word_logits = self.semantic_output(context)\n",
    "        sentiment_logits = self.sentiment_output(context)\n",
    "        return center_word_logits, sentiment_logits\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "351ba061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the model\n",
    "model1 = CDSAWESModel1(vocab_size=vocab_size, embedding_dim=embedding_dim)\n",
    "\n",
    "# Compile the model with appropriate loss functions and optimizer\n",
    "model1.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss={\n",
    "        'semantic_output': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        'sentiment_output': tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    },\n",
    "    loss_weights={\n",
    "        'semantic_output': beta,\n",
    "        'sentiment_output': 1 - beta\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "94111806",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mY_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "Y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "41df2bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "       array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "       array([0., 0., 0., ..., 0., 0., 0.]), ...,\n",
       "       array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "       array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "       array([0., 0., 0., ..., 0., 0., 0.])], dtype=object)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a51a17b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for training\n",
    "# Convert X_train to a suitable format\n",
    "# Flatten the list of DataFrames into a single DataFrame\n",
    "#x_train_tensor = X_train['Context_word']\n",
    "# Prepare the dataset for training\n",
    "# Convert X_train to a suitable format\n",
    "# Flatten the list of DataFrames into a single DataFrame\n",
    "\n",
    "# Convert the DataFrame to a one-hot encoded tensor\n",
    "#y_train_center = Y_train['Center_word'].values\n",
    "#y_train_sentiment = Y_train['Sentiment_label'].values\n",
    "\n",
    "# Define the dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dbd26f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train is a pandas DataFrame with a 'Context' column containing the one-hot encoded lists\n",
    "context_array = np.stack(X_train['Context'].values)  # Convert the column of lists to a NumPy array\n",
    "context_tensor = tf.convert_to_tensor(context_array, dtype=tf.float32)  # Convert the NumPy array to a Tensor\n",
    "\n",
    "# Assuming Y_train is a pandas DataFrame with 'center_word' and 'sentiment_label' columns\n",
    "center_word_targets = np.stack(Y_train['Center_word'].values)\n",
    "sentiment_targets = Y_train['Sentiment_label'].values\n",
    "\n",
    "# Convert targets to Tensors\n",
    "center_word_targets_tensor = tf.convert_to_tensor(center_word_targets, dtype=tf.int64)\n",
    "sentiment_targets_tensor = tf.convert_to_tensor(sentiment_targets, dtype=tf.float32)  # Use tf.int64 if it's categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a5ba9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((context_tensor, (center_word_targets_tensor, sentiment_targets_tensor )))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1568c39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Temp\\__autograph_generated_file_k1ltjkk.py\", line 13, in tf__call\n        center_word_logits = ag__.converted_call(ag__.ld(self).semantic_output, (ag__.ld(context),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'cdsawes_model1_2' (type CDSAWESModel1).\n    \n    in user code:\n    \n        File \"C:\\Users\\CCC-PC\\AppData\\Local\\Temp\\ipykernel_12124\\2945418648.py\", line 16, in call  *\n            center_word_logits = self.semantic_output(context)\n        File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Input 0 of layer \"dense_1\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (2,)\n    \n    \n    Call arguments received by layer 'cdsawes_model1_2' (type CDSAWESModel1):\n      • inputs=tf.Tensor(shape=(2, 1952), dtype=float32)\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileo8nni864.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_k1ltjkk.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     11\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39membedding, (ag__\u001b[38;5;241m.\u001b[39mld(corrupted),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m context \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_sum, (ag__\u001b[38;5;241m.\u001b[39mld(embeddings),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), fscope)\n\u001b[1;32m---> 13\u001b[0m center_word_logits \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msemantic_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m sentiment_logits \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39msentiment_output, (ag__\u001b[38;5;241m.\u001b[39mld(context),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Temp\\__autograph_generated_file_k1ltjkk.py\", line 13, in tf__call\n        center_word_logits = ag__.converted_call(ag__.ld(self).semantic_output, (ag__.ld(context),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'cdsawes_model1_2' (type CDSAWESModel1).\n    \n    in user code:\n    \n        File \"C:\\Users\\CCC-PC\\AppData\\Local\\Temp\\ipykernel_12124\\2945418648.py\", line 16, in call  *\n            center_word_logits = self.semantic_output(context)\n        File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Input 0 of layer \"dense_1\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (2,)\n    \n    \n    Call arguments received by layer 'cdsawes_model1_2' (type CDSAWESModel1):\n      • inputs=tf.Tensor(shape=(2, 1952), dtype=float32)\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "model1.fit(train_dataset, epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6afcfc",
   "metadata": {},
   "source": [
    "## Basic CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2ee4bb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"custom_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  100000    \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  110000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 210000 (820.31 KB)\n",
      "Trainable params: 210000 (820.31 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 10 # you can choose your own number\n",
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=vocab_size)\n",
    "        # We assume that the input to the model will be one-hot encoded, making the embedding layer effectively act as W1 matrix multiplication + bias\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        # Reduce along the sequence dimension to simulate the effect of W1*x + b\n",
    "        # This step is necessary because the embedding layer expects sequence data.\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        hidden_representation = self.dense(x)\n",
    "        return hidden_representation\n",
    "model2 = CustomModel(vocab_size, EMBEDDING_DIM)\n",
    "\n",
    "# Example input (one-hot encoded for demonstration purposes, but you should use integer encoding with an Embedding layer)\n",
    "# For real usage, the input should be the indices of words, not one-hot encoded vectors, to leverage the Embedding layer efficiently.\n",
    "x_input = tf.keras.Input(shape=(vocab_size,))\n",
    "\n",
    "# Get the model's output\n",
    "hidden_representation = model2(x_input)\n",
    "\n",
    "# Compile the model (if you have specific loss and optimizer)\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Model summary\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1c54f530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1115,\n",
       " 7731,\n",
       " 794,\n",
       " 3390,\n",
       " 2778,\n",
       " 7639,\n",
       " 5085,\n",
       " 1128,\n",
       " 4734,\n",
       " 3309,\n",
       " 4165,\n",
       " 10803,\n",
       " 9868,\n",
       " 7363,\n",
       " 3818,\n",
       " 7639,\n",
       " 2476,\n",
       " 1265,\n",
       " 2272,\n",
       " 3045,\n",
       " 1048,\n",
       " 4103,\n",
       " 7482,\n",
       " 4448,\n",
       " 2580,\n",
       " 4368,\n",
       " 6658,\n",
       " 1729,\n",
       " 10312,\n",
       " 3049,\n",
       " 4129,\n",
       " 3226,\n",
       " 2714,\n",
       " 7041,\n",
       " 435,\n",
       " 190,\n",
       " 8726,\n",
       " 9042,\n",
       " 67,\n",
       " 10406,\n",
       " 7761,\n",
       " 7241,\n",
       " 5751,\n",
       " 7083,\n",
       " 4483,\n",
       " 7834,\n",
       " 8605,\n",
       " 9246,\n",
       " 2190,\n",
       " 787,\n",
       " 5095,\n",
       " 1474,\n",
       " 10779,\n",
       " 1355,\n",
       " 4859,\n",
       " 8726,\n",
       " 4924,\n",
       " 5515,\n",
       " 7639,\n",
       " 7461,\n",
       " 7639,\n",
       " 9785,\n",
       " 6703,\n",
       " 1084,\n",
       " 4597,\n",
       " 3988,\n",
       " 4796,\n",
       " 4560,\n",
       " 5128,\n",
       " 1891,\n",
       " 8076,\n",
       " 1701,\n",
       " 7639,\n",
       " 10406,\n",
       " 553,\n",
       " 1115,\n",
       " 4834,\n",
       " 91,\n",
       " 4513,\n",
       " 5937,\n",
       " 2514,\n",
       " 7569,\n",
       " 6751,\n",
       " 5140,\n",
       " 2481,\n",
       " 101,\n",
       " 1193,\n",
       " 6387,\n",
       " 1973,\n",
       " 6072,\n",
       " 8620,\n",
       " 6615,\n",
       " 9171,\n",
       " 5751,\n",
       " 2439,\n",
       " 952,\n",
       " 1931,\n",
       " 4371,\n",
       " 10063,\n",
       " 3898,\n",
       " 6703,\n",
       " 9262,\n",
       " 8020,\n",
       " 2823,\n",
       " 5166,\n",
       " 2597,\n",
       " 10804,\n",
       " 6997,\n",
       " 514,\n",
       " 4975,\n",
       " 609,\n",
       " 9454,\n",
       " 7281,\n",
       " 7319,\n",
       " 6200,\n",
       " 5529,\n",
       " 4825,\n",
       " 1097,\n",
       " 310,\n",
       " 2310,\n",
       " 4695,\n",
       " 8926,\n",
       " 3673,\n",
       " 3711,\n",
       " 4878,\n",
       " 3742,\n",
       " 8251,\n",
       " 6253,\n",
       " 1567,\n",
       " 2869,\n",
       " 2482,\n",
       " 5810,\n",
       " 7252,\n",
       " 8445,\n",
       " 5818,\n",
       " 1610,\n",
       " 2976,\n",
       " 1498,\n",
       " 2155,\n",
       " 10648,\n",
       " 7521,\n",
       " 6372,\n",
       " 9773,\n",
       " 10653,\n",
       " 594,\n",
       " 9562,\n",
       " 4644,\n",
       " 10535,\n",
       " 1100,\n",
       " 3754,\n",
       " 2977,\n",
       " 4859,\n",
       " 4873,\n",
       " 5206,\n",
       " 10242,\n",
       " 1155,\n",
       " 1108,\n",
       " 9078,\n",
       " 4467,\n",
       " 1380,\n",
       " 6200,\n",
       " 8506,\n",
       " 2047,\n",
       " 6196,\n",
       " 5216,\n",
       " 2156,\n",
       " 4129,\n",
       " 3096,\n",
       " 5054,\n",
       " 4821,\n",
       " 2131,\n",
       " 91,\n",
       " 8344,\n",
       " 553,\n",
       " 7521,\n",
       " 423,\n",
       " 5677,\n",
       " 4403,\n",
       " 6021,\n",
       " 8726,\n",
       " 2269,\n",
       " 2429,\n",
       " 5649,\n",
       " 505,\n",
       " 10044,\n",
       " 6353,\n",
       " 10617,\n",
       " 7496,\n",
       " 9990,\n",
       " 3150,\n",
       " 7284,\n",
       " 2851,\n",
       " 3635,\n",
       " 8726,\n",
       " 2777,\n",
       " 10368,\n",
       " 7964,\n",
       " 1679,\n",
       " 7639,\n",
       " 1864,\n",
       " 8864,\n",
       " 8926,\n",
       " 6075,\n",
       " 3623,\n",
       " 6848,\n",
       " 4293,\n",
       " 3758,\n",
       " 8924,\n",
       " 3687,\n",
       " 2567,\n",
       " 4857,\n",
       " 4171,\n",
       " 10591,\n",
       " 10021,\n",
       " 3308,\n",
       " 2851,\n",
       " 4924,\n",
       " 5669,\n",
       " 4859,\n",
       " 4343,\n",
       " 9990,\n",
       " 9193,\n",
       " 6246,\n",
       " 1058,\n",
       " 299,\n",
       " 5669,\n",
       " 9134,\n",
       " 3970,\n",
       " 635,\n",
       " 165,\n",
       " 3274,\n",
       " 1840,\n",
       " 5429,\n",
       " 7639,\n",
       " 10109,\n",
       " 2404,\n",
       " 6476,\n",
       " 10187,\n",
       " 3896,\n",
       " 8403,\n",
       " 2042,\n",
       " 4859,\n",
       " 9795,\n",
       " 7482,\n",
       " 6287,\n",
       " 4438,\n",
       " 8499,\n",
       " 1669,\n",
       " 10304,\n",
       " 10025,\n",
       " 6951,\n",
       " 9503,\n",
       " 9629,\n",
       " 2277,\n",
       " 1891,\n",
       " 9413,\n",
       " 8926,\n",
       " 6201,\n",
       " 7823,\n",
       " 10084,\n",
       " 8995,\n",
       " 9883,\n",
       " 8170,\n",
       " 4783,\n",
       " 4246,\n",
       " 5780,\n",
       " 9010,\n",
       " 2148,\n",
       " 8767,\n",
       " 5358,\n",
       " 9244,\n",
       " 289,\n",
       " 236,\n",
       " 10481,\n",
       " 1338,\n",
       " 8926,\n",
       " 4796,\n",
       " 3946,\n",
       " 5513,\n",
       " 2201,\n",
       " 3007,\n",
       " 4924,\n",
       " 5166,\n",
       " 7639,\n",
       " 9140,\n",
       " 4721,\n",
       " 7442,\n",
       " 6074,\n",
       " 9629,\n",
       " 5739,\n",
       " 6382,\n",
       " 3124,\n",
       " 7416,\n",
       " 7822,\n",
       " 5867,\n",
       " 2087,\n",
       " 9640,\n",
       " 10025,\n",
       " 3473,\n",
       " 633,\n",
       " 8808,\n",
       " 6670,\n",
       " 9629,\n",
       " 8726,\n",
       " 3736,\n",
       " 3875,\n",
       " 9629,\n",
       " 7639,\n",
       " 9076,\n",
       " 6344,\n",
       " 5961,\n",
       " 7926,\n",
       " 8726,\n",
       " 4796,\n",
       " 5695,\n",
       " 119,\n",
       " 4796,\n",
       " 6083,\n",
       " 2934,\n",
       " 3662,\n",
       " 5170,\n",
       " 2069,\n",
       " 7761,\n",
       " 3681,\n",
       " 5166,\n",
       " 6004,\n",
       " 9925,\n",
       " 8349,\n",
       " 9495,\n",
       " 9314,\n",
       " 218,\n",
       " 2597,\n",
       " 8921,\n",
       " 10219,\n",
       " 10742,\n",
       " 3077,\n",
       " 8184,\n",
       " 9640,\n",
       " 6508,\n",
       " 2255,\n",
       " 6368,\n",
       " 7003,\n",
       " 9486,\n",
       " 588,\n",
       " 8592,\n",
       " 9462,\n",
       " 1744,\n",
       " 91,\n",
       " 6908,\n",
       " 9493,\n",
       " 5639,\n",
       " 6108,\n",
       " 8173,\n",
       " 5669,\n",
       " 953,\n",
       " 2302,\n",
       " 3377,\n",
       " 3748,\n",
       " 1962,\n",
       " 6100,\n",
       " 10395,\n",
       " 4514,\n",
       " 3634,\n",
       " 3812,\n",
       " 9159,\n",
       " 7090,\n",
       " 8157,\n",
       " 606,\n",
       " 2319,\n",
       " 8151,\n",
       " 9310,\n",
       " 6073,\n",
       " 1342,\n",
       " 5891,\n",
       " 1857,\n",
       " 4196,\n",
       " 3038,\n",
       " 8140,\n",
       " 2509,\n",
       " 9056,\n",
       " 5802,\n",
       " 1859,\n",
       " 9193,\n",
       " 4739,\n",
       " 1484,\n",
       " 7021,\n",
       " 8058,\n",
       " 500,\n",
       " 333,\n",
       " 1241,\n",
       " 3003,\n",
       " 9452,\n",
       " 7368,\n",
       " 689,\n",
       " 5691,\n",
       " 61,\n",
       " 6852,\n",
       " 9764,\n",
       " 9425,\n",
       " 8762,\n",
       " 2223,\n",
       " 9222,\n",
       " 4284,\n",
       " 5696,\n",
       " 10120,\n",
       " 4145,\n",
       " 2476,\n",
       " 4848,\n",
       " 10435,\n",
       " 2699,\n",
       " 487,\n",
       " 3451,\n",
       " 5851,\n",
       " 7229,\n",
       " 6645,\n",
       " 7639,\n",
       " 6023,\n",
       " 2070,\n",
       " 1917,\n",
       " 2423,\n",
       " 4924,\n",
       " 729,\n",
       " 681,\n",
       " 8195,\n",
       " 2263,\n",
       " 3104,\n",
       " 2486,\n",
       " 165,\n",
       " 9010,\n",
       " 10455,\n",
       " 5941,\n",
       " 2726,\n",
       " 505,\n",
       " 629,\n",
       " 649,\n",
       " 10465,\n",
       " 7681,\n",
       " 4859,\n",
       " 2378,\n",
       " 5307,\n",
       " 4638,\n",
       " 1999,\n",
       " 5409,\n",
       " 7321,\n",
       " 1085,\n",
       " 85,\n",
       " 1332,\n",
       " 3038,\n",
       " 7053,\n",
       " 8926,\n",
       " 1539,\n",
       " 8061,\n",
       " 5363,\n",
       " 2304,\n",
       " 4023,\n",
       " 2555,\n",
       " 6140,\n",
       " 10111,\n",
       " 2169,\n",
       " 5685,\n",
       " 9169,\n",
       " 2779,\n",
       " 6327,\n",
       " 6464,\n",
       " 7469,\n",
       " 2409,\n",
       " 8297,\n",
       " 4628,\n",
       " 6613,\n",
       " 8050,\n",
       " 1131,\n",
       " 9084,\n",
       " 1104,\n",
       " 3932,\n",
       " 4868,\n",
       " 6148,\n",
       " 245,\n",
       " 5891,\n",
       " 3422,\n",
       " 8726,\n",
       " 782,\n",
       " 8995,\n",
       " 8928,\n",
       " 7058,\n",
       " 7639,\n",
       " 6167,\n",
       " 4923,\n",
       " 9597,\n",
       " 2337,\n",
       " 7639,\n",
       " 6624,\n",
       " 10793,\n",
       " 834,\n",
       " 4181,\n",
       " 1009,\n",
       " 4595,\n",
       " 5579,\n",
       " 2560,\n",
       " 10537,\n",
       " 7861,\n",
       " 3237,\n",
       " 1341,\n",
       " 5341,\n",
       " 3052,\n",
       " 3598,\n",
       " 10578,\n",
       " 1089,\n",
       " 10627,\n",
       " 5515,\n",
       " 6036,\n",
       " 1097,\n",
       " 1931,\n",
       " 9658,\n",
       " 4590,\n",
       " 1115,\n",
       " 84,\n",
       " 8288,\n",
       " 8733,\n",
       " 3716,\n",
       " 4566,\n",
       " 1541,\n",
       " 5751,\n",
       " 5503,\n",
       " 2005,\n",
       " 1498,\n",
       " 4886,\n",
       " 5054,\n",
       " 1349,\n",
       " 5751,\n",
       " 7683,\n",
       " 3326,\n",
       " 7639,\n",
       " 3808,\n",
       " 8127,\n",
       " 6113,\n",
       " 9187,\n",
       " 1610,\n",
       " 2654,\n",
       " 9286,\n",
       " 3253,\n",
       " 4639,\n",
       " 5730,\n",
       " 7278,\n",
       " 6156,\n",
       " 7192,\n",
       " 3457,\n",
       " 3608,\n",
       " 10070,\n",
       " 1973,\n",
       " 10099,\n",
       " 6284,\n",
       " 5209,\n",
       " 1008,\n",
       " 7639,\n",
       " 2240,\n",
       " 2789,\n",
       " 326,\n",
       " 9281,\n",
       " 899,\n",
       " 7947,\n",
       " 4996,\n",
       " 4871,\n",
       " 8726,\n",
       " 6728,\n",
       " 1757,\n",
       " 5745,\n",
       " 6508,\n",
       " 4834,\n",
       " 3970,\n",
       " 2023,\n",
       " 8817,\n",
       " 7866,\n",
       " 1212,\n",
       " 9054,\n",
       " 10025,\n",
       " 1768,\n",
       " 863,\n",
       " 10708,\n",
       " 6703,\n",
       " 5006,\n",
       " 10187,\n",
       " 8869,\n",
       " 3235,\n",
       " 7483,\n",
       " 9124,\n",
       " 2597,\n",
       " 8726,\n",
       " 166,\n",
       " 7497,\n",
       " 5361,\n",
       " 3007,\n",
       " 10435,\n",
       " 8115,\n",
       " 3872,\n",
       " 7814,\n",
       " 4898,\n",
       " 4226,\n",
       " 737,\n",
       " 1108,\n",
       " 4145,\n",
       " 8597,\n",
       " 9719,\n",
       " 9292,\n",
       " 8726,\n",
       " 5087,\n",
       " 7712,\n",
       " 10585,\n",
       " 9963,\n",
       " 4686,\n",
       " 1805,\n",
       " 282,\n",
       " 5582,\n",
       " 6697,\n",
       " 6902,\n",
       " 2851,\n",
       " 2274,\n",
       " 7284,\n",
       " 1973,\n",
       " 962,\n",
       " 4061,\n",
       " 6353,\n",
       " 1330,\n",
       " 6015,\n",
       " 4409,\n",
       " 7509,\n",
       " 9425,\n",
       " 2755,\n",
       " 6464,\n",
       " 6912,\n",
       " 8217,\n",
       " 5505,\n",
       " 5751,\n",
       " 6681,\n",
       " 5872,\n",
       " 7283,\n",
       " 1642,\n",
       " 903,\n",
       " 4713,\n",
       " 980,\n",
       " 3119,\n",
       " 5669,\n",
       " 7394,\n",
       " 1317,\n",
       " 7585,\n",
       " 4370,\n",
       " 4293,\n",
       " 563,\n",
       " 9657,\n",
       " 10824,\n",
       " 9792,\n",
       " 5649,\n",
       " 834,\n",
       " 5515,\n",
       " 4502,\n",
       " 7066,\n",
       " 4083,\n",
       " 9418,\n",
       " 7791,\n",
       " 7266,\n",
       " 1241,\n",
       " 6221,\n",
       " 2817,\n",
       " 1858,\n",
       " 7090,\n",
       " 4129,\n",
       " 5494,\n",
       " 1884,\n",
       " 10012,\n",
       " 7087,\n",
       " 3233,\n",
       " 4859,\n",
       " 4125,\n",
       " 10736,\n",
       " 5485,\n",
       " 355,\n",
       " 4226,\n",
       " 1794,\n",
       " 3439,\n",
       " 9308,\n",
       " 9393,\n",
       " 1629,\n",
       " 5004,\n",
       " 3226,\n",
       " 5956,\n",
       " 7284,\n",
       " 6312,\n",
       " 5802,\n",
       " 9857,\n",
       " 6846,\n",
       " 3766,\n",
       " 1336,\n",
       " 6792,\n",
       " 8701,\n",
       " 8124,\n",
       " 501,\n",
       " 2723,\n",
       " 3515,\n",
       " 7639,\n",
       " 9307,\n",
       " 6662,\n",
       " 5108,\n",
       " 5172,\n",
       " 5922,\n",
       " 1987,\n",
       " 4742,\n",
       " 5450,\n",
       " 4803,\n",
       " 7639,\n",
       " 1582,\n",
       " 3688,\n",
       " 835,\n",
       " 1677,\n",
       " 6035,\n",
       " 4893,\n",
       " 8236,\n",
       " 10488,\n",
       " 7826,\n",
       " 8971,\n",
       " 4729,\n",
       " 8510,\n",
       " 6995,\n",
       " 1235,\n",
       " 8726,\n",
       " 970,\n",
       " 8154,\n",
       " 7452,\n",
       " 1408,\n",
       " 2063,\n",
       " 7257,\n",
       " 1048,\n",
       " 4859,\n",
       " 6167,\n",
       " 7639,\n",
       " 3627,\n",
       " 10185,\n",
       " 9135,\n",
       " 9671,\n",
       " 9425,\n",
       " 254,\n",
       " 4207,\n",
       " 4343,\n",
       " 803,\n",
       " 6703,\n",
       " 4007,\n",
       " 7639,\n",
       " 7379,\n",
       " 1085,\n",
       " 8585,\n",
       " 9719,\n",
       " 10611,\n",
       " 9511,\n",
       " 2739,\n",
       " 10185,\n",
       " 5033,\n",
       " 6942,\n",
       " 7493,\n",
       " 2498,\n",
       " 779,\n",
       " 5920,\n",
       " 10221,\n",
       " 72,\n",
       " 5040,\n",
       " 9613,\n",
       " 2777,\n",
       " 6302,\n",
       " 1918,\n",
       " 7639,\n",
       " 4145,\n",
       " 5669,\n",
       " 505,\n",
       " 4610,\n",
       " 245,\n",
       " 253,\n",
       " 5194,\n",
       " 8096,\n",
       " 5799,\n",
       " 7152,\n",
       " 10639,\n",
       " 8726,\n",
       " 4066,\n",
       " 275,\n",
       " 6633,\n",
       " 5482,\n",
       " 6995,\n",
       " 10252,\n",
       " 1946,\n",
       " 8926,\n",
       " 190,\n",
       " 6009,\n",
       " 5905,\n",
       " 5469,\n",
       " 10161,\n",
       " 7489,\n",
       " 3038,\n",
       " 7824,\n",
       " 5751,\n",
       " 4859,\n",
       " 3223,\n",
       " 8837,\n",
       " 3718,\n",
       " 3802,\n",
       " 6800,\n",
       " 3221,\n",
       " 1128,\n",
       " 3731,\n",
       " 2709,\n",
       " 10435,\n",
       " 9555,\n",
       " 8997,\n",
       " 9391,\n",
       " 5139,\n",
       " 2682,\n",
       " 5926,\n",
       " 3822,\n",
       " 2211,\n",
       " 3015,\n",
       " 4793,\n",
       " 4537,\n",
       " 4687,\n",
       " 9220,\n",
       " 9169,\n",
       " 10767,\n",
       " 6994,\n",
       " 6909,\n",
       " 4742,\n",
       " 4766,\n",
       " 8003,\n",
       " 253,\n",
       " 2399,\n",
       " 583,\n",
       " 7806,\n",
       " 2777,\n",
       " 6948,\n",
       " 2201,\n",
       " 6935,\n",
       " 2917,\n",
       " 2404,\n",
       " 4196,\n",
       " 2319,\n",
       " 3080,\n",
       " 8726,\n",
       " 5684,\n",
       " 6703,\n",
       " 3366,\n",
       " 3266,\n",
       " 4262,\n",
       " 8856,\n",
       " 10752,\n",
       " 6646,\n",
       " 7639,\n",
       " 10545,\n",
       " 6733,\n",
       " 3933,\n",
       " 9081,\n",
       " 8453,\n",
       " 9361,\n",
       " 9294,\n",
       " 7639,\n",
       " 5329,\n",
       " 4891,\n",
       " 2097,\n",
       " 10359,\n",
       " 6695,\n",
       " 709,\n",
       " 6703,\n",
       " 10252,\n",
       " 5745,\n",
       " 8273,\n",
       " 5751,\n",
       " 7918,\n",
       " 10042,\n",
       " 5385,\n",
       " 8875,\n",
       " 9222,\n",
       " 10702,\n",
       " 8726,\n",
       " 3834,\n",
       " 2597,\n",
       " 5216,\n",
       " 4607,\n",
       " 3829,\n",
       " 6703,\n",
       " 2407,\n",
       " 702,\n",
       " 9307,\n",
       " 5918,\n",
       " 6166,\n",
       " 6615,\n",
       " 8476,\n",
       " 10189,\n",
       " 4815,\n",
       " 1397,\n",
       " 1163,\n",
       " 9899,\n",
       " 8461,\n",
       " 9315,\n",
       " 10185,\n",
       " 2223,\n",
       " 1247,\n",
       " 4409,\n",
       " 3038,\n",
       " 1108,\n",
       " 5582,\n",
       " 1432,\n",
       " 1687,\n",
       " 2654,\n",
       " 1085,\n",
       " 10444,\n",
       " 7712,\n",
       " 9413,\n",
       " 10202,\n",
       " 2652,\n",
       " 9723,\n",
       " 9169,\n",
       " 1961,\n",
       " 8801,\n",
       " 3686,\n",
       " 10042,\n",
       " 5201,\n",
       " 5780,\n",
       " 3788,\n",
       " 6093,\n",
       " 6072,\n",
       " 7286,\n",
       " 2777,\n",
       " 3237,\n",
       " 9320,\n",
       " 487,\n",
       " 6102,\n",
       " 1286,\n",
       " 3343,\n",
       " 4579,\n",
       " 8274,\n",
       " 8011,\n",
       " 7354,\n",
       " 3078,\n",
       " 9456,\n",
       " 1230,\n",
       " 484,\n",
       " 7639,\n",
       " 8263,\n",
       " 5572,\n",
       " 8783,\n",
       " 9309,\n",
       " 5705,\n",
       " 8539,\n",
       " 3399,\n",
       " 5751,\n",
       " 4120,\n",
       " 5691,\n",
       " 7199,\n",
       " 5649,\n",
       " 2429,\n",
       " 8626,\n",
       " 4607,\n",
       " 5751,\n",
       " 9307,\n",
       " 4876,\n",
       " 3682,\n",
       " 7557,\n",
       " 1028,\n",
       " 8726,\n",
       " 10312,\n",
       " 7708,\n",
       " 2611,\n",
       " 7639,\n",
       " 10495,\n",
       " 443,\n",
       " 3604,\n",
       " 1480,\n",
       " 2869,\n",
       " 2777,\n",
       " 1142,\n",
       " 4694,\n",
       " 5745,\n",
       " 505,\n",
       " 5529,\n",
       " 4641,\n",
       " 611,\n",
       " 2098,\n",
       " 1513,\n",
       " 1610,\n",
       " 9307,\n",
       " 3366,\n",
       " 4514,\n",
       " 2702,\n",
       " 6038,\n",
       " 9271,\n",
       " 2151,\n",
       " 3187,\n",
       " 9134,\n",
       " 1638,\n",
       " 3316,\n",
       " 5380,\n",
       " 7690,\n",
       " 8842,\n",
       " 10221,\n",
       " 6847,\n",
       " 941,\n",
       " 10755,\n",
       " ...]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1e6e4a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "context= np.array(X_train)\n",
    "target = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3add4820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31807, 2)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5b83af30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape\n",
    "type(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3404a478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10873) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m n_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file41o_rcwn.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10873) are incompatible\n"
     ]
    }
   ],
   "source": [
    "n_iters = 10\n",
    "model2.fit(context,target, epochs=n_iters, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a0981e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "       array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "       array([0., 0., 0., ..., 0., 0., 0.]), ...,\n",
       "       array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "       array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "       array([0., 0., 0., ..., 0., 0., 0.])], dtype=object)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1027353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#y_train = np.array(Y_train_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a6f2044f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "82a86929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([0., 0., 0., ..., 0., 0., 0.])]\n",
      " [array([0., 0., 0., ..., 0., 0., 0.])]\n",
      " [array([0., 0., 0., ..., 0., 0., 0.])]\n",
      " ...\n",
      " [array([0., 0., 0., ..., 0., 0., 0.])]\n",
      " [array([0., 0., 0., ..., 0., 0., 0.])]\n",
      " [array([0., 0., 0., ..., 0., 0., 0.])]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6ab3ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train = np.vstack(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b48bdd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = [[np.array([0., 0., 0., 0., 0., 0.])], [np.array([0., 0., 0., 0., 0., 0.])]]\n",
    "\n",
    "\n",
    "matrix = np.vstack([row[0] for row in data])\n",
    "\n",
    "\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2f36c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Train = Y_train['Center_word'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffbe24ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m y\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43my_train\u001b[49m:\n\u001b[0;32m      3\u001b[0m     y\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "y=[]\n",
    "for x in y_train:\n",
    "    y.append(x.tolist())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "18ed644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_Train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a7d82a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[(3254, 10873), (7759, 10873)]\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(X_train[ 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e9e5a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Lambda\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "549d8ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\CCC-PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "994/994 [==============================] - 49s 46ms/step - loss: 8.9601\n",
      "Epoch 2/10\n",
      "994/994 [==============================] - 46s 46ms/step - loss: 8.1232\n",
      "Epoch 3/10\n",
      "994/994 [==============================] - 46s 46ms/step - loss: 7.5489\n",
      "Epoch 4/10\n",
      "994/994 [==============================] - 46s 46ms/step - loss: 6.7328\n",
      "Epoch 5/10\n",
      "994/994 [==============================] - 46s 46ms/step - loss: 5.6405\n",
      "Epoch 6/10\n",
      "994/994 [==============================] - 46s 46ms/step - loss: 4.3812\n",
      "Epoch 7/10\n",
      "994/994 [==============================] - 46s 46ms/step - loss: 3.1486\n",
      "Epoch 8/10\n",
      "994/994 [==============================] - 46s 46ms/step - loss: 2.1474\n",
      "Epoch 9/10\n",
      "994/994 [==============================] - 46s 46ms/step - loss: 1.4547\n",
      "Epoch 10/10\n",
      "994/994 [==============================] - 46s 46ms/step - loss: 1.0204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x160b1e09110>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocabsize, output_dim=embedding_dim, input_length=context.shape[1]),\n",
    "    Lambda(lambda x: tf.reduce_mean(x, axis=1)),  # Averaging embedding vectors\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Convert target to categorical\n",
    "#target = tf.keras.utils.to_categorical(target, num_classes=vocab_size)\n",
    "\n",
    "# Train the model\n",
    "model.fit(context, target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3b4c07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
